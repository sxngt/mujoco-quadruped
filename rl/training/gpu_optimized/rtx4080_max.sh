#!/bin/bash
"""
RTX 4080 GPU ìµœëŒ€ í™œìš© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
GPU ì‚¬ìš©ë¥  80% ëª©í‘œ
"""

echo "ğŸš€ RTX 4080 ìµœëŒ€ í™œìš© í•™ìŠµ ì‹œì‘"
echo "GPU ì •ë³´ í™•ì¸ ì¤‘..."

# GPU ì •ë³´ ì¶œë ¥
nvidia-smi

echo ""
echo "ğŸ”¥ GPU ìµœì í™” í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"

# CUDA ìµœì í™”
export CUDA_LAUNCH_BLOCKING=0
export TORCH_CUDA_ARCH_LIST="8.6"  # RTX 4080 Ampere ì•„í‚¤í…ì²˜
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,expandable_segments:True"

# cuDNN ìµœì í™”
export CUDNN_BENCHMARK=1
export CUDNN_DETERMINISTIC=0

# PyTorch ìµœì í™”
export OMP_NUM_THREADS=8
export PYTORCH_TENSOREXPR_FALLBACK=0

echo "í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ"
echo ""

# ì‚¬ìš©ì ì„ íƒ ë©”ë‰´
echo "RTX 4080 ìµœì í™” í•™ìŠµ ëª¨ë“œ ì„ íƒ:"
echo "1) ğŸ”¥ GPU ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ (64 í™˜ê²½, GPU 80% ëª©í‘œ)"
echo "2) âš¡ GPU ê³ ì„±ëŠ¥ ëª¨ë“œ (48 í™˜ê²½, GPU 60% ëª©í‘œ)"  
echo "3) ğŸ¯ GPU ì•ˆì • ëª¨ë“œ (32 í™˜ê²½, GPU 40% ëª©í‘œ)"
echo "4) ğŸš€ ë²¡í„°í™” ìµœëŒ€ ëª¨ë“œ (64 í™˜ê²½, CPU+GPU í˜¼í•©)"
echo "5) âš¡ ë²¡í„°í™” ê³ ì„±ëŠ¥ ëª¨ë“œ (32 í™˜ê²½, CPU+GPU í˜¼í•©)"
echo "6) ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ (16 í™˜ê²½, ë‹¨ì‹œê°„ í…ŒìŠ¤íŠ¸)"

read -p "ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1-6): " mode

case $mode in
    1)
        echo "ğŸ”¥ ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ ì‹œì‘"
        uv run python gpu_max_train.py \
            --num_envs 64 \
            --total_timesteps 20000000 \
            --rollout_length 16384 \
            --batch_size 2048 \
            --hidden_dim 512 \
            --lr 1e-4 \
            --ppo_epochs 20 \
            --mixed_precision \
            --wandb \
            --save_freq 500000
        ;;
    2)
        echo "âš¡ ê³ ì„±ëŠ¥ ëª¨ë“œ ì‹œì‘"
        uv run python gpu_max_train.py \
            --num_envs 48 \
            --total_timesteps 15000000 \
            --rollout_length 12288 \
            --batch_size 1536 \
            --hidden_dim 512 \
            --lr 1e-4 \
            --ppo_epochs 15 \
            --mixed_precision \
            --wandb \
            --save_freq 400000
        ;;
    3)
        echo "ğŸ¯ ì•ˆì • ëª¨ë“œ ì‹œì‘"
        uv run python gpu_max_train.py \
            --num_envs 32 \
            --total_timesteps 10000000 \
            --rollout_length 8192 \
            --batch_size 1024 \
            --hidden_dim 512 \
            --lr 1e-4 \
            --ppo_epochs 12 \
            --mixed_precision \
            --wandb \
            --save_freq 300000
        ;;
    4)
        echo "ğŸš€ ë²¡í„°í™” ìµœëŒ€ ëª¨ë“œ ì‹œì‘"
        uv run python train_vectorized.py \
            --num_envs 64 \
            --total_timesteps 20000000 \
            --rollout_length 8192 \
            --batch_size 1024 \
            --lr 1e-4 \
            --ppo_epochs 15 \
            --no_reference_gait \
            --wandb \
            --save_freq 500000
        ;;
    5)
        echo "âš¡ ë²¡í„°í™” ê³ ì„±ëŠ¥ ëª¨ë“œ ì‹œì‘"
        uv run python train_vectorized.py \
            --num_envs 32 \
            --total_timesteps 15000000 \
            --rollout_length 4096 \
            --batch_size 512 \
            --lr 1e-4 \
            --ppo_epochs 12 \
            --no_reference_gait \
            --wandb \
            --save_freq 400000
        ;;
    6)
        echo "ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹œì‘"
        uv run python gpu_max_train.py \
            --num_envs 16 \
            --total_timesteps 1000000 \
            --rollout_length 4096 \
            --batch_size 512 \
            --hidden_dim 256 \
            --lr 3e-4 \
            --ppo_epochs 10 \
            --mixed_precision \
            --wandb \
            --save_freq 100000
        ;;
    *)
        echo "âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤."
        exit 1
        ;;
esac

echo ""
echo "âœ… í•™ìŠµ ì™„ë£Œ!"
echo "GPU ìƒíƒœ í™•ì¸:"
nvidia-smi